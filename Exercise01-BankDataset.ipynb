{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification on the Bank Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comes from the UCI Machine Learning repository (http://archive.ics.uci.edu/ml/index.php), and it is related to direct marketing campaigns (phone calls) of a Portuguese banking institution.\n",
    "\n",
    "The **classification goal** is to predict whether the client will subscribe to a term deposit (variable $y$, (1/0)). The dataset can be downloaded from: https://raw.githubusercontent.com/madmashup/targeted-marketing-predictive-engine/master/banking.csv\n",
    "\n",
    "The dataset provides the bank customers’ information. It includes 41,188 records and 21 fields.\n",
    "\n",
    "*Input variables*\n",
    "\n",
    "1. age (numeric)\n",
    "2. job: type of job (categorical: “admin”, “blue-collar”, “entrepreneur”, “housemaid”, “management”, “retired”, “self-employed”, “services”, “student”, “technician”, “unemployed”, “unknown”)\n",
    "3. marital: marital status (categorical: “divorced”, “married”, “single”, “unknown”)\n",
    "4. education (categorical: “basic.4y”, “basic.6y”, “basic.9y”, “high.school”, “illiterate”, “professional.course”, “university.degree”, “unknown”)\n",
    "5. default: has credit in default? (categorical: “no”, “yes”, “unknown”)\n",
    "6. housing: has housing loan? (categorical: “no”, “yes”, “unknown”)\n",
    "7. loan: has personal loan? (categorical: “no”, “yes”, “unknown”)\n",
    "8. contact: contact communication type (categorical: “cellular”, “telephone”)\n",
    "9. month: last contact month of year (categorical: “jan”, “feb”, “mar”, …, “nov”, “dec”)\n",
    "10. day_of_week: last contact day of the week (categorical: “mon”, “tue”, “wed”, “thu”, “fri”)\n",
    "11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y=’no’). The duration is not known before a call is performed, also, after the end of the call, y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model\n",
    "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14. previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15. poutcome: outcome of the previous marketing campaign (categorical: “failure”, “nonexistent”, “success”)\n",
    "16. emp.var.rate: employment variation rate — (numeric)\n",
    "17. cons.price.idx: consumer price index — (numeric)\n",
    "18. cons.conf.idx: consumer confidence index — (numeric)\n",
    "19. euribor3m: euribor 3 month rate — (numeric)\n",
    "20. nr.employed: number of employees — (numeric)\n",
    "\n",
    "*Predict variable* (desired target):\n",
    "\n",
    "* has the client subscribed a term deposit? (binary: “1”, means “Yes”, “0” means “No”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.02406</td>\n",
       "      <td>258.285010</td>\n",
       "      <td>2.567593</td>\n",
       "      <td>962.475454</td>\n",
       "      <td>0.172963</td>\n",
       "      <td>0.081886</td>\n",
       "      <td>93.575664</td>\n",
       "      <td>-40.502600</td>\n",
       "      <td>3.621291</td>\n",
       "      <td>5167.035911</td>\n",
       "      <td>0.112654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.42125</td>\n",
       "      <td>259.279249</td>\n",
       "      <td>2.770014</td>\n",
       "      <td>186.910907</td>\n",
       "      <td>0.494901</td>\n",
       "      <td>1.570960</td>\n",
       "      <td>0.578840</td>\n",
       "      <td>4.628198</td>\n",
       "      <td>1.734447</td>\n",
       "      <td>72.251528</td>\n",
       "      <td>0.316173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>92.201000</td>\n",
       "      <td>-50.800000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>4963.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.00000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-42.700000</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>5099.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>93.749000</td>\n",
       "      <td>-41.800000</td>\n",
       "      <td>4.857000</td>\n",
       "      <td>5191.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.00000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>93.994000</td>\n",
       "      <td>-36.400000</td>\n",
       "      <td>4.961000</td>\n",
       "      <td>5228.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.00000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>94.767000</td>\n",
       "      <td>-26.900000</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>5228.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age      duration      campaign         pdays      previous  \\\n",
       "count  41188.00000  41188.000000  41188.000000  41188.000000  41188.000000   \n",
       "mean      40.02406    258.285010      2.567593    962.475454      0.172963   \n",
       "std       10.42125    259.279249      2.770014    186.910907      0.494901   \n",
       "min       17.00000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%       32.00000    102.000000      1.000000    999.000000      0.000000   \n",
       "50%       38.00000    180.000000      2.000000    999.000000      0.000000   \n",
       "75%       47.00000    319.000000      3.000000    999.000000      0.000000   \n",
       "max       98.00000   4918.000000     56.000000    999.000000      7.000000   \n",
       "\n",
       "       emp_var_rate  cons_price_idx  cons_conf_idx     euribor3m  \\\n",
       "count  41188.000000    41188.000000   41188.000000  41188.000000   \n",
       "mean       0.081886       93.575664     -40.502600      3.621291   \n",
       "std        1.570960        0.578840       4.628198      1.734447   \n",
       "min       -3.400000       92.201000     -50.800000      0.634000   \n",
       "25%       -1.800000       93.075000     -42.700000      1.344000   \n",
       "50%        1.100000       93.749000     -41.800000      4.857000   \n",
       "75%        1.400000       93.994000     -36.400000      4.961000   \n",
       "max        1.400000       94.767000     -26.900000      5.045000   \n",
       "\n",
       "        nr_employed             y  \n",
       "count  41188.000000  41188.000000  \n",
       "mean    5167.035911      0.112654  \n",
       "std       72.251528      0.316173  \n",
       "min     4963.600000      0.000000  \n",
       "25%     5099.100000      0.000000  \n",
       "50%     5191.000000      0.000000  \n",
       "75%     5228.100000      0.000000  \n",
       "max     5228.100000      1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"banking.csv\", header=0)\n",
    "data = data.dropna()\n",
    "\n",
    "print(data.shape)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basic.4y' 'unknown' 'university.degree' 'high.school' 'basic.9y'\n",
      " 'professional.course' 'basic.6y' 'illiterate']\n"
     ]
    }
   ],
   "source": [
    "print(data[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = data.columns[data.dtypes.eq('object')]\n",
    "\n",
    "data[object_columns] = data[object_columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "print(data[\"education\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is:  (41188, 11)\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=1, inplace=True)\n",
    "\n",
    "print(\"Shape is: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36548\n",
       "1     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFDlJREFUeJzt3X+sX/V93/HnCxsSti4Dgkep7c2osVY52WrIrfHW/pERFQzSZlolEUwtLkNxpsCUSFUV6B8jJWFKtKSodAmSOxxM1cVh+TG8yplnUbIoUvlxWShgKOKOkGHLgVvMj2RRQabv/fH93PCtude+2J/v/frmPh/S0T3f9/l8zvkcyfJL55zP93xTVUiS1MMp4x6AJOmnh6EiSerGUJEkdWOoSJK6MVQkSd0YKpKkbgwVSVI3hookqRtDRZLUzfJxD2ChnX322bVmzZpxD0OSFpWHHnror6pqxbHaLblQWbNmDZOTk+MehiQtKkm+P5923v6SJHVjqEiSujFUJEndGCqSpG4MFUlSN4aKJKkbQ0WS1I2hIknqxlCRJHWz5L5Rf6Le+zt3jnsIOgk99B+vGvcQpJOCVyqSpG4MFUlSN4aKJKkbQ0WS1M3IQiXJ25M8kOQvkuxL8nutfkeS7yV5uC3rWz1Jbk0yleSRJBcM7WtLkqfasmWo/t4kj7Y+tybJqM5HknRso5z99SpwUVX9KMmpwHeSfLNt+52q+uoR7S8F1rblQuA24MIkZwE3AhNAAQ8l2VVVL7Y2HwbuB3YDm4BvIkkai5FdqdTAj9rHU9tSR+myGbiz9bsPOCPJucAlwN6qOtSCZC+wqW17R1XdV1UF3AlcPqrzkSQd20ifqSRZluRh4HkGwXB/23Rzu8V1S5K3tdpK4Nmh7vtb7Wj1/bPUZxvH1iSTSSanp6dP+LwkSbMbaahU1etVtR5YBWxI8h7gBuAXgF8CzgI+McoxtHFsq6qJqppYseKYP7EsSTpOCzL7q6peAu4FNlXVwXaL61XgS8CG1uwAsHqo26pWO1p91Sx1SdKYjHL214okZ7T104FfBf6yPQuhzdS6HHisddkFXNVmgW0EXq6qg8Ae4OIkZyY5E7gY2NO2vZJkY9vXVcDdozofSdKxjXL217nAjiTLGITXXVX1p0n+LMkKIMDDwL9t7XcDlwFTwI+BqwGq6lCSTwEPtnY3VdWhtv5R4A7gdAazvpz5JUljNLJQqapHgPNnqV80R/sCrp1j23Zg+yz1SeA9JzZSSVIvfqNektSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1M7JQSfL2JA8k+Ysk+5L8Xqufl+T+JFNJvpLktFZ/W/s81bavGdrXDa3+ZJJLhuqbWm0qyfWjOhdJ0vyM8krlVeCiqvpFYD2wKclG4LPALVX1LuBF4JrW/hrgxVa/pbUjyTrgCuDdwCbgi0mWJVkGfAG4FFgHXNnaSpLGZGShUgM/ah9PbUsBFwFfbfUdwOVtfXP7TNv+/iRp9Z1V9WpVfQ+YAja0Zaqqnq6q14Cdra0kaUxG+kylXVE8DDwP7AX+D/BSVR1uTfYDK9v6SuBZgLb9ZeCdw/Uj+sxVlySNyUhDpaper6r1wCoGVxa/MMrjzSXJ1iSTSSanp6fHMQRJWhIWZPZXVb0E3Av8M+CMJMvbplXAgbZ+AFgN0Lb/feCF4foRfeaqz3b8bVU1UVUTK1as6HJOkqQ3G+XsrxVJzmjrpwO/CjzBIFw+0JptAe5u67vaZ9r2P6uqavUr2uyw84C1wAPAg8DaNpvsNAYP83eN6nwkSce2/NhNjtu5wI42S+sU4K6q+tMkjwM7k3wa+C5we2t/O/DHSaaAQwxCgqral+Qu4HHgMHBtVb0OkOQ6YA+wDNheVftGeD6SpGMYWahU1SPA+bPUn2bwfOXI+l8DH5xjXzcDN89S3w3sPuHBSpK68Bv1kqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpm5GFSpLVSe5N8niSfUk+1uqfTHIgycNtuWyozw1JppI8meSSofqmVptKcv1Q/bwk97f6V5KcNqrzkSQd2yivVA4Dv11V64CNwLVJ1rVtt1TV+rbsBmjbrgDeDWwCvphkWZJlwBeAS4F1wJVD+/ls29e7gBeBa0Z4PpKkYxhZqFTVwar63239h8ATwMqjdNkM7KyqV6vqe8AUsKEtU1X1dFW9BuwENicJcBHw1dZ/B3D5aM5GkjQfC/JMJcka4Hzg/la6LskjSbYnObPVVgLPDnXb32pz1d8JvFRVh4+oS5LGZOShkuRngK8BH6+qV4DbgJ8H1gMHgc8vwBi2JplMMjk9PT3qw0nSkjXSUElyKoNA+ZOq+jpAVT1XVa9X1d8Af8Tg9hbAAWD1UPdVrTZX/QXgjCTLj6i/SVVtq6qJqppYsWJFn5OTJL3JKGd/BbgdeKKqfn+ofu5Qs18DHmvru4ArkrwtyXnAWuAB4EFgbZvpdRqDh/m7qqqAe4EPtP5bgLtHdT6SpGNbfuwmx+2Xgd8EHk3ycKv9LoPZW+uBAp4BPgJQVfuS3AU8zmDm2LVV9TpAkuuAPcAyYHtV7Wv7+wSwM8mnge8yCDFJ0piMLFSq6jtAZtm0+yh9bgZunqW+e7Z+VfU0b9w+kySNmd+olyR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6mZeoZLknvnUJElL21F/+THJ24G/A5yd5Eze+CXHdwArRzw2SdIic6yfE/4I8HHg54CHeCNUXgH+0wjHJUlahI4aKlX1B8AfJPl3VfWHCzQmSdIiNa9nKlX1h0n+eZJ/neSqmeVofZKsTnJvkseT7EvysVY/K8neJE+1v2e2epLcmmQqySNJLhja15bW/qkkW4bq703yaOtza5K8eSSSpIUy3wf1fwx8DvgV4JfaMnGMboeB366qdcBG4Nok64DrgXuqai1wT/sMcCmwti1bgdvasc8CbgQuBDYAN84EUWvz4aF+m+ZzPpKk0TjWM5UZE8C6qqr57riqDgIH2/oPkzzB4OH+ZuB9rdkO4FvAJ1r9znaM+5KckeTc1nZvVR0CSLIX2JTkW8A7quq+Vr8TuBz45nzHKEnqa77fU3kM+NnjPUiSNcD5wP3AOS1wAH4AnNPWVwLPDnXb32pHq++fpT7b8bcmmUwyOT09fbynIUk6hvleqZwNPJ7kAeDVmWJV/atjdUzyM8DXgI9X1SvDjz2qqpLM++rneFXVNmAbwMTExMiPJ0lL1XxD5ZPHs/MkpzIIlD+pqq+38nNJzq2qg+321vOtfgBYPdR9Vasd4I3bZTP1b7X6qlnaS5LGZL6zv/7XbMvR+rSZWLcDT1TV7w9t2gXMzODaAtw9VL+qzQLbCLzcbpPtAS5OcmZ7QH8xsKdteyXJxnasq4b2JUkag3ldqST5ITBz2+g04FTg/1XVO47S7ZeB3wQeTfJwq/0u8BngriTXAN8HPtS27QYuA6aAHwNXA1TVoSSfAh5s7W6aeWgPfBS4AzidwQN6H9JL0hjNK1Sq6u/NrLergs0Mpgkfrc93eOMb+Ed6/yztC7h2jn1tB7bPUp8E3nO0cUiSFs5bfktxDfw34JIRjEeStIjN9/bXrw99PIXB91b+eiQjkiQtWvOd/fUvh9YPA88wuAUmSdJPzPeZytWjHogkafGb77u/ViX5RpLn2/K1JKuO3VOStJTM90H9lxh8j+Tn2vLfW02SpJ+Yb6isqKovVdXhttwBrBjhuCRJi9B8Q+WFJL+RZFlbfgN4YZQDkyQtPvMNlX/D4JvvP2DwOvsPAL81ojFJkhap+U4pvgnYUlUvwk9+OOtzDMJGkiRg/lcq/3QmUGDwPi4Gv48iSdJPzDdUThn6Cd+ZK5X5XuVIkpaI+QbD54E/T/Jf2+cPAjePZkiSpMVqvt+ovzPJJHBRK/16VT0+umFJkhajed/CaiFikEiS5vSWX30vSdJcDBVJUjeGiiSpG0NFktTNyEIlyfb2mvzHhmqfTHIgycNtuWxo2w1JppI8meSSofqmVptKcv1Q/bwk97f6V5KcNqpzkSTNzyivVO4ANs1Sv6Wq1rdlN0CSdcAVwLtbny/OvLwS+AJwKbAOuLK1Bfhs29e7gBeBa0Z4LpKkeRhZqFTVt4FD82y+GdhZVa9W1feAKWBDW6aq6umqeg3YCWxOEgbfmflq678DuLzrCUiS3rJxPFO5Lskj7fbYzKtfVgLPDrXZ32pz1d8JvFRVh4+oS5LGaKFD5Tbg54H1DF6h//mFOGiSrUkmk0xOT08vxCElaUla0FCpqueq6vWq+hvgjxjc3gI4AKwearqq1eaqvwCckWT5EfW5jrutqiaqamLFCn+wUpJGZUFDJcm5Qx9/DZiZGbYLuCLJ25KcB6wFHgAeBNa2mV6nMXiYv6uqCriXwY+FAWwB7l6Ic5AkzW1kr69P8mXgfcDZSfYDNwLvS7IeKOAZ4CMAVbUvyV0M3i12GLi2ql5v+7kO2AMsA7ZX1b52iE8AO5N8GvgucPuozkWSND8jC5WqunKW8pz/8VfVzczyOv027Xj3LPWneeP2mSTpJOA36iVJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuDBVJUjcjC5Uk25M8n+SxodpZSfYmear9PbPVk+TWJFNJHklywVCfLa39U0m2DNXfm+TR1ufWJBnVuUiS5meUVyp3AJuOqF0P3FNVa4F72meAS4G1bdkK3AaDEAJuBC4ENgA3zgRRa/PhoX5HHkuStMBGFipV9W3g0BHlzcCOtr4DuHyofmcN3AeckeRc4BJgb1UdqqoXgb3AprbtHVV1X1UVcOfQviRJY7LQz1TOqaqDbf0HwDltfSXw7FC7/a12tPr+WeqSpDEa24P6doVRC3GsJFuTTCaZnJ6eXohDStKStNCh8ly7dUX7+3yrHwBWD7Vb1WpHq6+apT6rqtpWVRNVNbFixYoTPglJ0uwWOlR2ATMzuLYAdw/Vr2qzwDYCL7fbZHuAi5Oc2R7QXwzsadteSbKxzfq6amhfkqQxWT6qHSf5MvA+4Owk+xnM4voMcFeSa4DvAx9qzXcDlwFTwI+BqwGq6lCSTwEPtnY3VdXMw/+PMphhdjrwzbZIksZoZKFSVVfOsen9s7Qt4No59rMd2D5LfRJ4z4mMUZLUl9+olyR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIkroxVCRJ3RgqkqRuxhIqSZ5J8miSh5NMttpZSfYmear9PbPVk+TWJFNJHklywdB+trT2TyXZMo5zkSS9YZxXKv+iqtZX1UT7fD1wT1WtBe5pnwEuBda2ZStwGwxCCLgRuBDYANw4E0SSpPE4mW5/bQZ2tPUdwOVD9Ttr4D7gjCTnApcAe6vqUFW9COwFNi30oCVJbxhXqBTwP5M8lGRrq51TVQfb+g+Ac9r6SuDZob77W22u+psk2ZpkMsnk9PR0r3OQJB1h+ZiO+ytVdSDJPwD2JvnL4Y1VVUmq18GqahuwDWBiYqLbfiVJf9tYrlSq6kD7+zzwDQbPRJ5rt7Vof59vzQ8Aq4e6r2q1ueqSpDFZ8CuVJH8XOKWqftjWLwZuAnYBW4DPtL93ty67gOuS7GTwUP7lqjqYZA/wH4Yezl8M3LCApyKddP7vTf9k3EPQSegf/vtHF+xY47j9dQ7wjSQzx/8vVfU/kjwI3JXkGuD7wIda+93AZcAU8GPgaoCqOpTkU8CDrd1NVXVo4U5DknSkBQ+Vqnoa+MVZ6i8A75+lXsC1c+xrO7C99xglScfnZJpSLEla5AwVSVI3hookqRtDRZLUjaEiSerGUJEkdWOoSJK6MVQkSd0YKpKkbgwVSVI3hookqRtDRZLUjaEiSerGUJEkdWOoSJK6MVQkSd0YKpKkbgwVSVI3hookqZtFHypJNiV5MslUkuvHPR5JWsoWdagkWQZ8AbgUWAdcmWTdeEclSUvXog4VYAMwVVVPV9VrwE5g85jHJElL1mIPlZXAs0Of97eaJGkMlo97AAshyVZga/v4oyRPjnM8P0XOBv5q3IM4GeRzW8Y9BL2Z/z5n3Jgee/lH82m02EPlALB66POqVvtbqmobsG2hBrVUJJmsqolxj0Oajf8+x2Ox3/56EFib5LwkpwFXALvGPCZJWrIW9ZVKVR1Och2wB1gGbK+qfWMeliQtWYs6VACqajewe9zjWKK8paiTmf8+xyBVNe4xSJJ+Siz2ZyqSpJOIoaLj4utxdLJKsj3J80keG/dYliJDRW+Zr8fRSe4OYNO4B7FUGSo6Hr4eRyetqvo2cGjc41iqDBUdD1+PI2lWhookqRtDRcdjXq/HkbT0GCo6Hr4eR9KsDBW9ZVV1GJh5Pc4TwF2+HkcniyRfBv4c+MdJ9ie5ZtxjWkr8Rr0kqRuvVCRJ3RgqkqRuDBVJUjeGiiSpG0NFktSNoSJJ6sZQkSR1Y6hIY5TkpiQfH/p8c5KPjXNM0onwy4/SGCVZA3y9qi5IcgrwFLChql4Y68Ck47R83AOQlrKqeibJC0nOB84BvmugaDEzVKTx+8/AbwE/C2wf71CkE+PtL2nM2pueHwVOBdZW1etjHpJ03LxSkcasql5Lci/wkoGixc5QkcasPaDfCHxw3GORTpRTiqUxSrIOmALuqaqnxj0e6UT5TEWS1I1XKpKkbgwVSVI3hookqRtDRZLUjaEiSerGUJEkdfP/AZaz5LjYSsNcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'y', data = data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No subscriptions (%):  88.73458288821988\n",
      "Subscription (%):  11.265417111780131\n"
     ]
    }
   ],
   "source": [
    "count_no_sub = len(data[data['y']==0])\n",
    "count_sub = len(data[data['y']==1])\n",
    "\n",
    "pct_of_no_sub = count_no_sub / (count_no_sub+count_sub)\n",
    "print(\"No subscriptions (%): \", pct_of_no_sub * 100)\n",
    "\n",
    "pct_of_sub = count_sub/(count_no_sub+count_sub)\n",
    "print(\"Subscription (%): \", pct_of_sub * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y']\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "cols = data.columns.values.tolist()\n",
    "print(cols)\n",
    "print(len(cols))\n",
    "\n",
    "X = data[cols[0:10]].values\n",
    "y_true = data['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler (standardize features by removing the mean and scaling to unit variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultra-basic two layers network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "adamLooksForRoberto = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adamLooksForRoberto, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "28831/28831 [==============================] - 3s 120us/step - loss: 0.2570 - acc: 0.9019\n",
      "Epoch 2/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.2025 - acc: 0.9102\n",
      "Epoch 3/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1991 - acc: 0.9087\n",
      "Epoch 4/100\n",
      "28831/28831 [==============================] - 3s 89us/step - loss: 0.1977 - acc: 0.9094\n",
      "Epoch 5/100\n",
      "28831/28831 [==============================] - 3s 89us/step - loss: 0.1971 - acc: 0.9090\n",
      "Epoch 6/100\n",
      "28831/28831 [==============================] - 3s 89us/step - loss: 0.1966 - acc: 0.9100\n",
      "Epoch 7/100\n",
      "28831/28831 [==============================] - 3s 89us/step - loss: 0.1962 - acc: 0.9087\n",
      "Epoch 8/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1958 - acc: 0.9095\n",
      "Epoch 9/100\n",
      "28831/28831 [==============================] - 3s 106us/step - loss: 0.1954 - acc: 0.9090\n",
      "Epoch 10/100\n",
      "28831/28831 [==============================] - 3s 115us/step - loss: 0.1952 - acc: 0.9097\n",
      "Epoch 11/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1949 - acc: 0.9088\n",
      "Epoch 12/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1944 - acc: 0.9096\n",
      "Epoch 13/100\n",
      "28831/28831 [==============================] - 3s 89us/step - loss: 0.1938 - acc: 0.9100\n",
      "Epoch 14/100\n",
      "28831/28831 [==============================] - 3s 89us/step - loss: 0.1933 - acc: 0.9104\n",
      "Epoch 15/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1931 - acc: 0.9099\n",
      "Epoch 16/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1927 - acc: 0.9103\n",
      "Epoch 17/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1922 - acc: 0.9107\n",
      "Epoch 18/100\n",
      "28831/28831 [==============================] - 3s 91us/step - loss: 0.1926 - acc: 0.9101\n",
      "Epoch 19/100\n",
      "28831/28831 [==============================] - 3s 97us/step - loss: 0.1919 - acc: 0.9100\n",
      "Epoch 20/100\n",
      "28831/28831 [==============================] - 3s 91us/step - loss: 0.1918 - acc: 0.9099\n",
      "Epoch 21/100\n",
      "28831/28831 [==============================] - 3s 92us/step - loss: 0.1913 - acc: 0.9106\n",
      "Epoch 22/100\n",
      "28831/28831 [==============================] - 3s 91us/step - loss: 0.1909 - acc: 0.9101\n",
      "Epoch 23/100\n",
      "28831/28831 [==============================] - 3s 92us/step - loss: 0.1902 - acc: 0.9107\n",
      "Epoch 24/100\n",
      "28831/28831 [==============================] - 3s 91us/step - loss: 0.1897 - acc: 0.9103\n",
      "Epoch 25/100\n",
      "28831/28831 [==============================] - 3s 107us/step - loss: 0.1890 - acc: 0.9104\n",
      "Epoch 26/100\n",
      "28831/28831 [==============================] - 3s 89us/step - loss: 0.1884 - acc: 0.9097\n",
      "Epoch 27/100\n",
      "28831/28831 [==============================] - 3s 87us/step - loss: 0.1879 - acc: 0.9103\n",
      "Epoch 28/100\n",
      "28831/28831 [==============================] - 3s 94us/step - loss: 0.1870 - acc: 0.9107: 0s - loss: 0.1869 - acc: 0\n",
      "Epoch 29/100\n",
      "28831/28831 [==============================] - 3s 94us/step - loss: 0.1866 - acc: 0.9105\n",
      "Epoch 30/100\n",
      "28831/28831 [==============================] - 3s 97us/step - loss: 0.1860 - acc: 0.9112\n",
      "Epoch 31/100\n",
      "28831/28831 [==============================] - 3s 96us/step - loss: 0.1856 - acc: 0.9113\n",
      "Epoch 32/100\n",
      "28831/28831 [==============================] - 3s 98us/step - loss: 0.1856 - acc: 0.9103: 1s - l\n",
      "Epoch 33/100\n",
      "28831/28831 [==============================] - 3s 95us/step - loss: 0.1851 - acc: 0.9105\n",
      "Epoch 34/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1848 - acc: 0.9109\n",
      "Epoch 35/100\n",
      "28831/28831 [==============================] - 2s 87us/step - loss: 0.1847 - acc: 0.9107\n",
      "Epoch 36/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1844 - acc: 0.9104\n",
      "Epoch 37/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1843 - acc: 0.9106\n",
      "Epoch 38/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1841 - acc: 0.9111\n",
      "Epoch 39/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1836 - acc: 0.9119\n",
      "Epoch 40/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1829 - acc: 0.9117\n",
      "Epoch 41/100\n",
      "28831/28831 [==============================] - 3s 88us/step - loss: 0.1827 - acc: 0.9117\n",
      "Epoch 42/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1819 - acc: 0.9130\n",
      "Epoch 43/100\n",
      "28831/28831 [==============================] - 3s 90us/step - loss: 0.1820 - acc: 0.9126\n",
      "Epoch 44/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1817 - acc: 0.9121\n",
      "Epoch 45/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1815 - acc: 0.9117\n",
      "Epoch 46/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1818 - acc: 0.9117\n",
      "Epoch 47/100\n",
      "28831/28831 [==============================] - 2s 87us/step - loss: 0.1813 - acc: 0.9123\n",
      "Epoch 48/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1812 - acc: 0.9128\n",
      "Epoch 49/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1808 - acc: 0.9135\n",
      "Epoch 50/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1810 - acc: 0.9130\n",
      "Epoch 51/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1812 - acc: 0.9124\n",
      "Epoch 52/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1808 - acc: 0.9135\n",
      "Epoch 53/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1809 - acc: 0.9123\n",
      "Epoch 54/100\n",
      "28831/28831 [==============================] - 2s 85us/step - loss: 0.1810 - acc: 0.9119\n",
      "Epoch 55/100\n",
      "28831/28831 [==============================] - 3s 88us/step - loss: 0.1809 - acc: 0.9117\n",
      "Epoch 56/100\n",
      "28831/28831 [==============================] - 3s 93us/step - loss: 0.1805 - acc: 0.9129\n",
      "Epoch 57/100\n",
      "28831/28831 [==============================] - 3s 93us/step - loss: 0.1806 - acc: 0.9131\n",
      "Epoch 58/100\n",
      "28831/28831 [==============================] - 3s 93us/step - loss: 0.1804 - acc: 0.9129: 1s - loss:\n",
      "Epoch 59/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1802 - acc: 0.9130\n",
      "Epoch 60/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1802 - acc: 0.9125\n",
      "Epoch 61/100\n",
      "28831/28831 [==============================] - 2s 87us/step - loss: 0.1806 - acc: 0.9132\n",
      "Epoch 62/100\n",
      "28831/28831 [==============================] - 2s 85us/step - loss: 0.1802 - acc: 0.9128\n",
      "Epoch 63/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1802 - acc: 0.9130: 0s - loss: 0.1801\n",
      "Epoch 64/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1802 - acc: 0.9133\n",
      "Epoch 65/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1801 - acc: 0.9132\n",
      "Epoch 66/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1801 - acc: 0.9127\n",
      "Epoch 67/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1800 - acc: 0.9130\n",
      "Epoch 68/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1797 - acc: 0.9130\n",
      "Epoch 69/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1799 - acc: 0.9123\n",
      "Epoch 70/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1802 - acc: 0.9129\n",
      "Epoch 71/100\n",
      "28831/28831 [==============================] - 3s 87us/step - loss: 0.1798 - acc: 0.9135\n",
      "Epoch 72/100\n",
      "28831/28831 [==============================] - 3s 89us/step - loss: 0.1797 - acc: 0.9139\n",
      "Epoch 73/100\n",
      "28831/28831 [==============================] - 3s 87us/step - loss: 0.1795 - acc: 0.9135\n",
      "Epoch 74/100\n",
      "28831/28831 [==============================] - 3s 94us/step - loss: 0.1796 - acc: 0.9134\n",
      "Epoch 75/100\n",
      "28831/28831 [==============================] - 3s 92us/step - loss: 0.1800 - acc: 0.9127\n",
      "Epoch 76/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1796 - acc: 0.9143\n",
      "Epoch 77/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1796 - acc: 0.9137\n",
      "Epoch 78/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1795 - acc: 0.9145\n",
      "Epoch 79/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1797 - acc: 0.9129\n",
      "Epoch 80/100\n",
      "28831/28831 [==============================] - 3s 87us/step - loss: 0.1795 - acc: 0.9128\n",
      "Epoch 81/100\n",
      "28831/28831 [==============================] - 2s 87us/step - loss: 0.1793 - acc: 0.9136\n",
      "Epoch 82/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1793 - acc: 0.9136\n",
      "Epoch 83/100\n",
      "28831/28831 [==============================] - 2s 87us/step - loss: 0.1797 - acc: 0.9132\n",
      "Epoch 84/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1797 - acc: 0.9136\n",
      "Epoch 85/100\n",
      "28831/28831 [==============================] - 2s 87us/step - loss: 0.1793 - acc: 0.9130\n",
      "Epoch 86/100\n",
      "28831/28831 [==============================] - 2s 87us/step - loss: 0.1793 - acc: 0.9137\n",
      "Epoch 87/100\n",
      "28831/28831 [==============================] - 2s 87us/step - loss: 0.1795 - acc: 0.9146\n",
      "Epoch 88/100\n",
      "28831/28831 [==============================] - 3s 87us/step - loss: 0.1796 - acc: 0.9129\n",
      "Epoch 89/100\n",
      "28831/28831 [==============================] - 3s 87us/step - loss: 0.1793 - acc: 0.9134\n",
      "Epoch 90/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1795 - acc: 0.9136\n",
      "Epoch 91/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1793 - acc: 0.9130\n",
      "Epoch 92/100\n",
      "28831/28831 [==============================] - 2s 85us/step - loss: 0.1791 - acc: 0.9145\n",
      "Epoch 93/100\n",
      "28831/28831 [==============================] - 3s 88us/step - loss: 0.1790 - acc: 0.9139\n",
      "Epoch 94/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1791 - acc: 0.9134\n",
      "Epoch 95/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1791 - acc: 0.9136\n",
      "Epoch 96/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1792 - acc: 0.9141\n",
      "Epoch 97/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1791 - acc: 0.9141\n",
      "Epoch 98/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1792 - acc: 0.9135\n",
      "Epoch 99/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1790 - acc: 0.9136: 0s - loss: 0.1792 - acc: 0.913\n",
      "Epoch 100/100\n",
      "28831/28831 [==============================] - 2s 86us/step - loss: 0.1790 - acc: 0.9140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1294bddd8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9146\n",
      "Epoch 2/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1775 - acc: 0.9142\n",
      "Epoch 3/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1776 - acc: 0.9146\n",
      "Epoch 4/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1776 - acc: 0.9145\n",
      "Epoch 5/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - acc: 0.9146\n",
      "Epoch 6/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - acc: 0.9143\n",
      "Epoch 7/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1778 - acc: 0.9141\n",
      "Epoch 8/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1778 - acc: 0.9147\n",
      "Epoch 9/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - acc: 0.9140\n",
      "Epoch 10/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9139\n",
      "Epoch 11/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1778 - acc: 0.9146\n",
      "Epoch 12/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9136\n",
      "Epoch 13/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9143\n",
      "Epoch 14/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1779 - acc: 0.9144\n",
      "Epoch 15/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1778 - acc: 0.9144\n",
      "Epoch 16/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9150\n",
      "Epoch 17/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - acc: 0.9147\n",
      "Epoch 18/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9141\n",
      "Epoch 19/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - acc: 0.9145\n",
      "Epoch 20/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9142\n",
      "Epoch 21/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1775 - acc: 0.9145\n",
      "Epoch 22/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9141\n",
      "Epoch 23/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1776 - acc: 0.9146\n",
      "Epoch 24/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1778 - acc: 0.9151\n",
      "Epoch 25/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - acc: 0.9153\n",
      "Epoch 26/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - acc: 0.9140\n",
      "Epoch 27/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1775 - acc: 0.9149\n",
      "Epoch 28/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - acc: 0.9144\n",
      "Epoch 29/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1774 - acc: 0.9150: 0s - loss: 0.1766 - acc: 0.91\n",
      "Epoch 30/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1773 - acc: 0.9153\n",
      "Epoch 31/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1776 - acc: 0.9145: 0s - loss: 0.1791 - acc: \n",
      "Epoch 32/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1774 - acc: 0.9146\n",
      "Epoch 33/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1776 - acc: 0.9143\n",
      "Epoch 34/100\n",
      "28831/28831 [==============================] - 1s 20us/step - loss: 0.1774 - acc: 0.9147\n",
      "Epoch 35/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1774 - acc: 0.9144\n",
      "Epoch 36/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1775 - acc: 0.9144\n",
      "Epoch 37/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1773 - acc: 0.9151\n",
      "Epoch 38/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1773 - acc: 0.9147\n",
      "Epoch 39/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - acc: 0.9144\n",
      "Epoch 40/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - acc: 0.9151\n",
      "Epoch 41/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1775 - acc: 0.9143\n",
      "Epoch 42/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1773 - acc: 0.9145\n",
      "Epoch 43/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9147\n",
      "Epoch 44/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - acc: 0.9141\n",
      "Epoch 45/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - acc: 0.9146\n",
      "Epoch 46/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - acc: 0.9144\n",
      "Epoch 47/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1773 - acc: 0.9151\n",
      "Epoch 48/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9146\n",
      "Epoch 49/100\n",
      "28831/28831 [==============================] - 1s 20us/step - loss: 0.1773 - acc: 0.9151\n",
      "Epoch 50/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - acc: 0.9139\n",
      "Epoch 51/100\n",
      "28831/28831 [==============================] - 1s 20us/step - loss: 0.1773 - acc: 0.9148\n",
      "Epoch 52/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1773 - acc: 0.9147\n",
      "Epoch 53/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1772 - acc: 0.9146\n",
      "Epoch 54/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1773 - acc: 0.9152\n",
      "Epoch 55/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1773 - acc: 0.9150\n",
      "Epoch 56/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1773 - acc: 0.9146\n",
      "Epoch 57/100\n",
      "28831/28831 [==============================] - 1s 20us/step - loss: 0.1773 - acc: 0.9150\n",
      "Epoch 58/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1773 - acc: 0.9146\n",
      "Epoch 59/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1774 - acc: 0.9146\n",
      "Epoch 60/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1770 - acc: 0.9150\n",
      "Epoch 61/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9148\n",
      "Epoch 62/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - acc: 0.9145\n",
      "Epoch 63/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1773 - acc: 0.9151\n",
      "Epoch 64/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1773 - acc: 0.9144\n",
      "Epoch 65/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1772 - acc: 0.9147\n",
      "Epoch 66/100\n",
      "28831/28831 [==============================] - 1s 20us/step - loss: 0.1772 - acc: 0.9152\n",
      "Epoch 67/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1774 - acc: 0.9152\n",
      "Epoch 68/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1773 - acc: 0.9141\n",
      "Epoch 69/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9145\n",
      "Epoch 70/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1771 - acc: 0.9148\n",
      "Epoch 71/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1772 - acc: 0.9149\n",
      "Epoch 72/100\n",
      "28831/28831 [==============================] - 1s 20us/step - loss: 0.1773 - acc: 0.9147\n",
      "Epoch 73/100\n",
      "28831/28831 [==============================] - 1s 20us/step - loss: 0.1772 - acc: 0.9147\n",
      "Epoch 74/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1771 - acc: 0.9151\n",
      "Epoch 75/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1772 - acc: 0.9144\n",
      "Epoch 76/100\n",
      "28831/28831 [==============================] - 1s 20us/step - loss: 0.1773 - acc: 0.9143\n",
      "Epoch 77/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9147\n",
      "Epoch 78/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1773 - acc: 0.9149\n",
      "Epoch 79/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1772 - acc: 0.9146\n",
      "Epoch 80/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1770 - acc: 0.9140\n",
      "Epoch 81/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1771 - acc: 0.9147\n",
      "Epoch 82/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9147\n",
      "Epoch 83/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1771 - acc: 0.9141\n",
      "Epoch 84/100\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1771 - acc: 0.9146\n",
      "Epoch 85/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9146\n",
      "Epoch 86/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9148\n",
      "Epoch 87/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1773 - acc: 0.9155\n",
      "Epoch 88/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1773 - acc: 0.9147\n",
      "Epoch 89/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9147\n",
      "Epoch 90/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1770 - acc: 0.9148\n",
      "Epoch 91/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1771 - acc: 0.9153\n",
      "Epoch 92/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9149\n",
      "Epoch 93/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9145\n",
      "Epoch 94/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9144\n",
      "Epoch 95/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9148\n",
      "Epoch 96/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1769 - acc: 0.9147\n",
      "Epoch 97/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1770 - acc: 0.9150\n",
      "Epoch 98/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9148\n",
      "Epoch 99/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9144\n",
      "Epoch 100/100\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1772 - acc: 0.9146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129984c18>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one layer more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "adamLooksForRoberto = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adamLooksForRoberto, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 171\n",
      "Trainable params: 171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.3748 - acc: 0.8935\n",
      "Epoch 2/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.2114 - acc: 0.9061\n",
      "Epoch 3/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.2050 - acc: 0.9077\n",
      "Epoch 4/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.2016 - acc: 0.9086\n",
      "Epoch 5/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.2000 - acc: 0.9089\n",
      "Epoch 6/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1992 - acc: 0.9099\n",
      "Epoch 7/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1986 - acc: 0.9093\n",
      "Epoch 8/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1982 - acc: 0.9093\n",
      "Epoch 9/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1978 - acc: 0.9091\n",
      "Epoch 10/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1975 - acc: 0.9091\n",
      "Epoch 11/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1972 - acc: 0.9095\n",
      "Epoch 12/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1971 - acc: 0.9092\n",
      "Epoch 13/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1968 - acc: 0.9092\n",
      "Epoch 14/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1966 - acc: 0.9099\n",
      "Epoch 15/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1963 - acc: 0.9093\n",
      "Epoch 16/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1963 - acc: 0.9096\n",
      "Epoch 17/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1960 - acc: 0.9100\n",
      "Epoch 18/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1958 - acc: 0.9092\n",
      "Epoch 19/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1956 - acc: 0.9096\n",
      "Epoch 20/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1953 - acc: 0.9099\n",
      "Epoch 21/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1952 - acc: 0.9101\n",
      "Epoch 22/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1949 - acc: 0.9101\n",
      "Epoch 23/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1948 - acc: 0.9100\n",
      "Epoch 24/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1946 - acc: 0.9102\n",
      "Epoch 25/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1945 - acc: 0.9096\n",
      "Epoch 26/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1942 - acc: 0.9097\n",
      "Epoch 27/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1939 - acc: 0.9097\n",
      "Epoch 28/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1938 - acc: 0.9100\n",
      "Epoch 29/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1936 - acc: 0.9104\n",
      "Epoch 30/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1935 - acc: 0.9102\n",
      "Epoch 31/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1930 - acc: 0.9104\n",
      "Epoch 32/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1929 - acc: 0.9101\n",
      "Epoch 33/100\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1927 - acc: 0.9100\n",
      "Epoch 34/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1916 - acc: 0.9111\n",
      "Epoch 35/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1913 - acc: 0.9116\n",
      "Epoch 36/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1908 - acc: 0.9115\n",
      "Epoch 37/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1905 - acc: 0.9115\n",
      "Epoch 38/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1903 - acc: 0.9122\n",
      "Epoch 39/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1902 - acc: 0.9117\n",
      "Epoch 40/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1899 - acc: 0.9121\n",
      "Epoch 41/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1898 - acc: 0.9120\n",
      "Epoch 42/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1897 - acc: 0.9114\n",
      "Epoch 43/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1895 - acc: 0.9121\n",
      "Epoch 44/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1896 - acc: 0.9121: 0s - loss: 0.1925 \n",
      "Epoch 45/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1893 - acc: 0.9120: 0s - loss: 0.1880 - acc: 0.91\n",
      "Epoch 46/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1892 - acc: 0.9123\n",
      "Epoch 47/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1891 - acc: 0.9116\n",
      "Epoch 48/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1891 - acc: 0.9120\n",
      "Epoch 49/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1889 - acc: 0.9117\n",
      "Epoch 50/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1888 - acc: 0.9124\n",
      "Epoch 51/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1887 - acc: 0.9124\n",
      "Epoch 52/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1888 - acc: 0.9127\n",
      "Epoch 53/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1887 - acc: 0.9120\n",
      "Epoch 54/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1885 - acc: 0.9124\n",
      "Epoch 55/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1884 - acc: 0.9127\n",
      "Epoch 56/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1882 - acc: 0.9127\n",
      "Epoch 57/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1883 - acc: 0.9120\n",
      "Epoch 58/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1882 - acc: 0.9130\n",
      "Epoch 59/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1881 - acc: 0.9121\n",
      "Epoch 60/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1880 - acc: 0.9121\n",
      "Epoch 61/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1879 - acc: 0.9125\n",
      "Epoch 62/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1876 - acc: 0.9120\n",
      "Epoch 63/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1877 - acc: 0.9127\n",
      "Epoch 64/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1876 - acc: 0.9121\n",
      "Epoch 65/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1874 - acc: 0.9136\n",
      "Epoch 66/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1874 - acc: 0.9125\n",
      "Epoch 67/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1876 - acc: 0.9121\n",
      "Epoch 68/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1872 - acc: 0.9129\n",
      "Epoch 69/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1872 - acc: 0.9122\n",
      "Epoch 70/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1871 - acc: 0.9127\n",
      "Epoch 71/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1869 - acc: 0.9125\n",
      "Epoch 72/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1870 - acc: 0.9121\n",
      "Epoch 73/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1867 - acc: 0.9127\n",
      "Epoch 74/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1868 - acc: 0.9119\n",
      "Epoch 75/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1865 - acc: 0.9127\n",
      "Epoch 76/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1866 - acc: 0.9127\n",
      "Epoch 77/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1865 - acc: 0.9123\n",
      "Epoch 78/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1864 - acc: 0.9125\n",
      "Epoch 79/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1862 - acc: 0.9117\n",
      "Epoch 80/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1861 - acc: 0.9122\n",
      "Epoch 81/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1860 - acc: 0.9123\n",
      "Epoch 82/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1859 - acc: 0.9117\n",
      "Epoch 83/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1857 - acc: 0.9117\n",
      "Epoch 84/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1855 - acc: 0.9124\n",
      "Epoch 85/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1855 - acc: 0.9121\n",
      "Epoch 86/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1853 - acc: 0.9120\n",
      "Epoch 87/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1852 - acc: 0.9122\n",
      "Epoch 88/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1851 - acc: 0.9123\n",
      "Epoch 89/100\n",
      "28831/28831 [==============================] - 1s 24us/step - loss: 0.1849 - acc: 0.9125\n",
      "Epoch 90/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1849 - acc: 0.9124: 0s - loss: 0.1845 - acc: 0.912\n",
      "Epoch 91/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1847 - acc: 0.9126\n",
      "Epoch 92/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1848 - acc: 0.9129\n",
      "Epoch 93/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1844 - acc: 0.9126\n",
      "Epoch 94/100\n",
      "28831/28831 [==============================] - 1s 22us/step - loss: 0.1845 - acc: 0.9127\n",
      "Epoch 95/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1843 - acc: 0.9123\n",
      "Epoch 96/100\n",
      "28831/28831 [==============================] - 1s 23us/step - loss: 0.1843 - acc: 0.9126\n",
      "Epoch 97/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1843 - acc: 0.9123\n",
      "Epoch 98/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1842 - acc: 0.9128\n",
      "Epoch 99/100\n",
      "28831/28831 [==============================] - 1s 21us/step - loss: 0.1841 - acc: 0.9130\n",
      "Epoch 100/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1840 - acc: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129c76e10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now using the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "adamLooksForRoberto = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adamLooksForRoberto, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 171\n",
      "Trainable params: 171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28831 samples, validate on 12357 samples\n",
      "Epoch 1/100\n",
      "28831/28831 [==============================] - 2s 62us/step - loss: 0.3260 - acc: 0.8852 - val_loss: 0.2106 - val_acc: 0.8886\n",
      "Epoch 2/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.2081 - acc: 0.8868 - val_loss: 0.2067 - val_acc: 0.8886\n",
      "Epoch 3/100\n",
      "28831/28831 [==============================] - 1s 38us/step - loss: 0.2055 - acc: 0.8913 - val_loss: 0.2043 - val_acc: 0.9137\n",
      "Epoch 4/100\n",
      "28831/28831 [==============================] - 1s 32us/step - loss: 0.2036 - acc: 0.9084 - val_loss: 0.2028 - val_acc: 0.9132\n",
      "Epoch 5/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.2020 - acc: 0.9086 - val_loss: 0.2011 - val_acc: 0.9137\n",
      "Epoch 6/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.2008 - acc: 0.9103 - val_loss: 0.1998 - val_acc: 0.9145\n",
      "Epoch 7/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.2000 - acc: 0.9104 - val_loss: 0.1989 - val_acc: 0.9132\n",
      "Epoch 8/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1993 - acc: 0.9104 - val_loss: 0.1982 - val_acc: 0.9154\n",
      "Epoch 9/100\n",
      "28831/28831 [==============================] - 1s 32us/step - loss: 0.1989 - acc: 0.9108 - val_loss: 0.1977 - val_acc: 0.9168\n",
      "Epoch 10/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1982 - acc: 0.9108 - val_loss: 0.1974 - val_acc: 0.9162\n",
      "Epoch 11/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1975 - acc: 0.9115 - val_loss: 0.1969 - val_acc: 0.9153\n",
      "Epoch 12/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1969 - acc: 0.9118 - val_loss: 0.1965 - val_acc: 0.9152\n",
      "Epoch 13/100\n",
      "28831/28831 [==============================] - 1s 32us/step - loss: 0.1965 - acc: 0.9118 - val_loss: 0.1970 - val_acc: 0.9139\n",
      "Epoch 14/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1961 - acc: 0.9117 - val_loss: 0.1960 - val_acc: 0.9137\n",
      "Epoch 15/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1959 - acc: 0.9117 - val_loss: 0.1958 - val_acc: 0.9138\n",
      "Epoch 16/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1954 - acc: 0.9125 - val_loss: 0.1964 - val_acc: 0.9140\n",
      "Epoch 17/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1953 - acc: 0.9115 - val_loss: 0.1956 - val_acc: 0.9166\n",
      "Epoch 18/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1951 - acc: 0.9118 - val_loss: 0.1952 - val_acc: 0.9162\n",
      "Epoch 19/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1947 - acc: 0.9122 - val_loss: 0.1951 - val_acc: 0.9149\n",
      "Epoch 20/100\n",
      "28831/28831 [==============================] - 1s 33us/step - loss: 0.1946 - acc: 0.9121 - val_loss: 0.1946 - val_acc: 0.9154\n",
      "Epoch 21/100\n",
      "28831/28831 [==============================] - 1s 32us/step - loss: 0.1945 - acc: 0.9122 - val_loss: 0.1953 - val_acc: 0.9153\n",
      "Epoch 22/100\n",
      "28831/28831 [==============================] - 1s 31us/step - loss: 0.1944 - acc: 0.9129 - val_loss: 0.1953 - val_acc: 0.9158\n",
      "Epoch 23/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1943 - acc: 0.9124 - val_loss: 0.1947 - val_acc: 0.9146\n",
      "Epoch 24/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1941 - acc: 0.9116 - val_loss: 0.1946 - val_acc: 0.9168\n",
      "Epoch 25/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1941 - acc: 0.9120 - val_loss: 0.1950 - val_acc: 0.9142\n",
      "Epoch 26/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1940 - acc: 0.9120 - val_loss: 0.1940 - val_acc: 0.9155\n",
      "Epoch 27/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1938 - acc: 0.9120 - val_loss: 0.1942 - val_acc: 0.9151\n",
      "Epoch 28/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1935 - acc: 0.9117 - val_loss: 0.1941 - val_acc: 0.9149\n",
      "Epoch 29/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1934 - acc: 0.9122 - val_loss: 0.1944 - val_acc: 0.9158\n",
      "Epoch 30/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1935 - acc: 0.9111 - val_loss: 0.1931 - val_acc: 0.9156\n",
      "Epoch 31/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1934 - acc: 0.9115 - val_loss: 0.1941 - val_acc: 0.9149\n",
      "Epoch 32/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1932 - acc: 0.9113 - val_loss: 0.1935 - val_acc: 0.9158\n",
      "Epoch 33/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1930 - acc: 0.9118 - val_loss: 0.1937 - val_acc: 0.9158\n",
      "Epoch 34/100\n",
      "28831/28831 [==============================] - 1s 31us/step - loss: 0.1929 - acc: 0.9113 - val_loss: 0.1934 - val_acc: 0.9149\n",
      "Epoch 35/100\n",
      "28831/28831 [==============================] - 1s 36us/step - loss: 0.1926 - acc: 0.9117 - val_loss: 0.1935 - val_acc: 0.9163\n",
      "Epoch 36/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1926 - acc: 0.9128 - val_loss: 0.1926 - val_acc: 0.9137\n",
      "Epoch 37/100\n",
      "28831/28831 [==============================] - 1s 34us/step - loss: 0.1924 - acc: 0.9113 - val_loss: 0.1930 - val_acc: 0.9148\n",
      "Epoch 38/100\n",
      "28831/28831 [==============================] - 1s 37us/step - loss: 0.1923 - acc: 0.9123 - val_loss: 0.1936 - val_acc: 0.9148\n",
      "Epoch 39/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1923 - acc: 0.9114 - val_loss: 0.1929 - val_acc: 0.9158\n",
      "Epoch 40/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1920 - acc: 0.9121 - val_loss: 0.1923 - val_acc: 0.9158\n",
      "Epoch 41/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1919 - acc: 0.9113 - val_loss: 0.1927 - val_acc: 0.9152\n",
      "Epoch 42/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1917 - acc: 0.9129 - val_loss: 0.1928 - val_acc: 0.9149\n",
      "Epoch 43/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1914 - acc: 0.9121 - val_loss: 0.1927 - val_acc: 0.9149\n",
      "Epoch 44/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1914 - acc: 0.9119 - val_loss: 0.1925 - val_acc: 0.9145\n",
      "Epoch 45/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1914 - acc: 0.9126 - val_loss: 0.1919 - val_acc: 0.9162\n",
      "Epoch 46/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1910 - acc: 0.9119 - val_loss: 0.1918 - val_acc: 0.9146\n",
      "Epoch 47/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1910 - acc: 0.9125 - val_loss: 0.1920 - val_acc: 0.9162\n",
      "Epoch 48/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1908 - acc: 0.9123 - val_loss: 0.1919 - val_acc: 0.9154\n",
      "Epoch 49/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1906 - acc: 0.9126 - val_loss: 0.1914 - val_acc: 0.9150\n",
      "Epoch 50/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1906 - acc: 0.9126 - val_loss: 0.1910 - val_acc: 0.9146\n",
      "Epoch 51/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1906 - acc: 0.9121 - val_loss: 0.1915 - val_acc: 0.9160\n",
      "Epoch 52/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1904 - acc: 0.9120 - val_loss: 0.1908 - val_acc: 0.9150\n",
      "Epoch 53/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1900 - acc: 0.9126 - val_loss: 0.1910 - val_acc: 0.9150\n",
      "Epoch 54/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1899 - acc: 0.9113 - val_loss: 0.1913 - val_acc: 0.9164\n",
      "Epoch 55/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1898 - acc: 0.9121 - val_loss: 0.1921 - val_acc: 0.9169\n",
      "Epoch 56/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1897 - acc: 0.9122 - val_loss: 0.1908 - val_acc: 0.9159\n",
      "Epoch 57/100\n",
      "28831/28831 [==============================] - 1s 33us/step - loss: 0.1892 - acc: 0.9118 - val_loss: 0.1908 - val_acc: 0.9173\n",
      "Epoch 58/100\n",
      "28831/28831 [==============================] - 1s 38us/step - loss: 0.1893 - acc: 0.9121 - val_loss: 0.1896 - val_acc: 0.9161\n",
      "Epoch 59/100\n",
      "28831/28831 [==============================] - 1s 40us/step - loss: 0.1892 - acc: 0.9125 - val_loss: 0.1899 - val_acc: 0.9152\n",
      "Epoch 60/100\n",
      "28831/28831 [==============================] - 1s 32us/step - loss: 0.1887 - acc: 0.9127 - val_loss: 0.1899 - val_acc: 0.9143\n",
      "Epoch 61/100\n",
      "28831/28831 [==============================] - 1s 33us/step - loss: 0.1886 - acc: 0.9121 - val_loss: 0.1894 - val_acc: 0.9169\n",
      "Epoch 62/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1884 - acc: 0.9117 - val_loss: 0.1896 - val_acc: 0.9163\n",
      "Epoch 63/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1882 - acc: 0.9118 - val_loss: 0.1900 - val_acc: 0.9162\n",
      "Epoch 64/100\n",
      "28831/28831 [==============================] - 1s 34us/step - loss: 0.1882 - acc: 0.9123 - val_loss: 0.1898 - val_acc: 0.9167\n",
      "Epoch 65/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1882 - acc: 0.9121 - val_loss: 0.1896 - val_acc: 0.9166\n",
      "Epoch 66/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1879 - acc: 0.9113 - val_loss: 0.1889 - val_acc: 0.9148\n",
      "Epoch 67/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1878 - acc: 0.9117 - val_loss: 0.1886 - val_acc: 0.9148\n",
      "Epoch 68/100\n",
      "28831/28831 [==============================] - 1s 34us/step - loss: 0.1879 - acc: 0.9118 - val_loss: 0.1885 - val_acc: 0.9178\n",
      "Epoch 69/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1876 - acc: 0.9112 - val_loss: 0.1887 - val_acc: 0.9153\n",
      "Epoch 70/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1875 - acc: 0.9118 - val_loss: 0.1887 - val_acc: 0.9161\n",
      "Epoch 71/100\n",
      "28831/28831 [==============================] - 1s 36us/step - loss: 0.1875 - acc: 0.9111 - val_loss: 0.1879 - val_acc: 0.9168\n",
      "Epoch 72/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1872 - acc: 0.9126 - val_loss: 0.1887 - val_acc: 0.9133\n",
      "Epoch 73/100\n",
      "28831/28831 [==============================] - 1s 40us/step - loss: 0.1872 - acc: 0.9122 - val_loss: 0.1877 - val_acc: 0.9158\n",
      "Epoch 74/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1868 - acc: 0.9119 - val_loss: 0.1882 - val_acc: 0.9166\n",
      "Epoch 75/100\n",
      "28831/28831 [==============================] - 1s 34us/step - loss: 0.1869 - acc: 0.9110 - val_loss: 0.1871 - val_acc: 0.9173\n",
      "Epoch 76/100\n",
      "28831/28831 [==============================] - 1s 33us/step - loss: 0.1866 - acc: 0.9117 - val_loss: 0.1883 - val_acc: 0.9141\n",
      "Epoch 77/100\n",
      "28831/28831 [==============================] - 1s 35us/step - loss: 0.1868 - acc: 0.9118 - val_loss: 0.1873 - val_acc: 0.9152\n",
      "Epoch 78/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1864 - acc: 0.9122 - val_loss: 0.1877 - val_acc: 0.9162\n",
      "Epoch 79/100\n",
      "28831/28831 [==============================] - 1s 30us/step - loss: 0.1864 - acc: 0.9121 - val_loss: 0.1882 - val_acc: 0.9161\n",
      "Epoch 80/100\n",
      "28831/28831 [==============================] - 1s 38us/step - loss: 0.1864 - acc: 0.9112 - val_loss: 0.1875 - val_acc: 0.9150\n",
      "Epoch 81/100\n",
      "28831/28831 [==============================] - 1s 31us/step - loss: 0.1862 - acc: 0.9120 - val_loss: 0.1871 - val_acc: 0.9170\n",
      "Epoch 82/100\n",
      "28831/28831 [==============================] - 1s 37us/step - loss: 0.1860 - acc: 0.9117 - val_loss: 0.1871 - val_acc: 0.9158\n",
      "Epoch 83/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1856 - acc: 0.9116 - val_loss: 0.1868 - val_acc: 0.9164\n",
      "Epoch 84/100\n",
      "28831/28831 [==============================] - 1s 40us/step - loss: 0.1859 - acc: 0.9112 - val_loss: 0.1870 - val_acc: 0.9154\n",
      "Epoch 85/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1856 - acc: 0.9115 - val_loss: 0.1863 - val_acc: 0.9179\n",
      "Epoch 86/100\n",
      "28831/28831 [==============================] - 1s 36us/step - loss: 0.1855 - acc: 0.9124 - val_loss: 0.1857 - val_acc: 0.9171\n",
      "Epoch 87/100\n",
      "28831/28831 [==============================] - 1s 31us/step - loss: 0.1852 - acc: 0.9121 - val_loss: 0.1855 - val_acc: 0.9171\n",
      "Epoch 88/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1852 - acc: 0.9125 - val_loss: 0.1860 - val_acc: 0.9183\n",
      "Epoch 89/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1853 - acc: 0.9122 - val_loss: 0.1855 - val_acc: 0.9162\n",
      "Epoch 90/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1849 - acc: 0.9119 - val_loss: 0.1859 - val_acc: 0.9166\n",
      "Epoch 91/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1845 - acc: 0.9128 - val_loss: 0.1860 - val_acc: 0.9166\n",
      "Epoch 92/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1846 - acc: 0.9116 - val_loss: 0.1857 - val_acc: 0.9164\n",
      "Epoch 93/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1846 - acc: 0.9116 - val_loss: 0.1848 - val_acc: 0.9168\n",
      "Epoch 94/100\n",
      "28831/28831 [==============================] - 1s 26us/step - loss: 0.1841 - acc: 0.9120 - val_loss: 0.1862 - val_acc: 0.9175\n",
      "Epoch 95/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1842 - acc: 0.9120 - val_loss: 0.1844 - val_acc: 0.9162\n",
      "Epoch 96/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1838 - acc: 0.9117 - val_loss: 0.1837 - val_acc: 0.9156\n",
      "Epoch 97/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1836 - acc: 0.9121 - val_loss: 0.1857 - val_acc: 0.9142\n",
      "Epoch 98/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1831 - acc: 0.9121 - val_loss: 0.1828 - val_acc: 0.9171\n",
      "Epoch 99/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1830 - acc: 0.9116 - val_loss: 0.1825 - val_acc: 0.9173\n",
      "Epoch 100/100\n",
      "28831/28831 [==============================] - 1s 25us/step - loss: 0.1824 - acc: 0.9125 - val_loss: 0.1833 - val_acc: 0.9166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129dee278>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28831 samples, validate on 12357 samples\n",
      "Epoch 1/100\n",
      "28831/28831 [==============================] - 0s 3us/step - loss: 0.1905 - acc: 0.9120 - val_loss: 0.1920 - val_acc: 0.9141\n",
      "Epoch 2/100\n",
      "28831/28831 [==============================] - 0s 3us/step - loss: 0.1903 - acc: 0.9125 - val_loss: 0.1919 - val_acc: 0.9141\n",
      "Epoch 3/100\n",
      "28831/28831 [==============================] - 0s 3us/step - loss: 0.1902 - acc: 0.9122 - val_loss: 0.1919 - val_acc: 0.9140\n",
      "Epoch 4/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1902 - acc: 0.9123 - val_loss: 0.1919 - val_acc: 0.9149\n",
      "Epoch 5/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1901 - acc: 0.9125 - val_loss: 0.1919 - val_acc: 0.9147\n",
      "Epoch 6/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1901 - acc: 0.9126 - val_loss: 0.1918 - val_acc: 0.9146\n",
      "Epoch 7/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1901 - acc: 0.9122 - val_loss: 0.1918 - val_acc: 0.9146\n",
      "Epoch 8/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1901 - acc: 0.9125 - val_loss: 0.1918 - val_acc: 0.9147\n",
      "Epoch 9/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1900 - acc: 0.9124 - val_loss: 0.1918 - val_acc: 0.9145\n",
      "Epoch 10/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1900 - acc: 0.9124 - val_loss: 0.1918 - val_acc: 0.9148\n",
      "Epoch 11/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1899 - acc: 0.9125 - val_loss: 0.1917 - val_acc: 0.9147\n",
      "Epoch 12/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1899 - acc: 0.9121 - val_loss: 0.1917 - val_acc: 0.9145\n",
      "Epoch 13/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1899 - acc: 0.9123 - val_loss: 0.1917 - val_acc: 0.9145\n",
      "Epoch 14/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1899 - acc: 0.9126 - val_loss: 0.1917 - val_acc: 0.9144\n",
      "Epoch 15/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1899 - acc: 0.9122 - val_loss: 0.1917 - val_acc: 0.9146\n",
      "Epoch 16/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1898 - acc: 0.9124 - val_loss: 0.1917 - val_acc: 0.9145\n",
      "Epoch 17/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1898 - acc: 0.9120 - val_loss: 0.1916 - val_acc: 0.9143\n",
      "Epoch 18/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1898 - acc: 0.9124 - val_loss: 0.1916 - val_acc: 0.9146\n",
      "Epoch 19/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1898 - acc: 0.9121 - val_loss: 0.1916 - val_acc: 0.9143\n",
      "Epoch 20/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1897 - acc: 0.9124 - val_loss: 0.1916 - val_acc: 0.9146\n",
      "Epoch 21/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1897 - acc: 0.9126 - val_loss: 0.1915 - val_acc: 0.9144\n",
      "Epoch 22/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1897 - acc: 0.9125 - val_loss: 0.1916 - val_acc: 0.9145\n",
      "Epoch 23/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1896 - acc: 0.9123 - val_loss: 0.1916 - val_acc: 0.9145\n",
      "Epoch 24/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1896 - acc: 0.9124 - val_loss: 0.1915 - val_acc: 0.9145\n",
      "Epoch 25/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1896 - acc: 0.9125 - val_loss: 0.1915 - val_acc: 0.9146\n",
      "Epoch 26/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1895 - acc: 0.9126 - val_loss: 0.1915 - val_acc: 0.9147\n",
      "Epoch 27/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1895 - acc: 0.9128 - val_loss: 0.1914 - val_acc: 0.9148\n",
      "Epoch 28/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1895 - acc: 0.9126 - val_loss: 0.1914 - val_acc: 0.9146\n",
      "Epoch 29/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1895 - acc: 0.9125 - val_loss: 0.1914 - val_acc: 0.9145\n",
      "Epoch 30/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1894 - acc: 0.9127 - val_loss: 0.1914 - val_acc: 0.9147\n",
      "Epoch 31/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1894 - acc: 0.9124 - val_loss: 0.1913 - val_acc: 0.9147\n",
      "Epoch 32/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1894 - acc: 0.9126 - val_loss: 0.1913 - val_acc: 0.9145\n",
      "Epoch 33/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1893 - acc: 0.9125 - val_loss: 0.1913 - val_acc: 0.9142\n",
      "Epoch 34/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1893 - acc: 0.9126 - val_loss: 0.1913 - val_acc: 0.9147\n",
      "Epoch 35/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1893 - acc: 0.9122 - val_loss: 0.1912 - val_acc: 0.9145\n",
      "Epoch 36/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1893 - acc: 0.9125 - val_loss: 0.1913 - val_acc: 0.9144\n",
      "Epoch 37/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1892 - acc: 0.9123 - val_loss: 0.1912 - val_acc: 0.9145\n",
      "Epoch 38/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1892 - acc: 0.9124 - val_loss: 0.1912 - val_acc: 0.9145\n",
      "Epoch 39/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1892 - acc: 0.9124 - val_loss: 0.1912 - val_acc: 0.9146\n",
      "Epoch 40/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1892 - acc: 0.9123 - val_loss: 0.1912 - val_acc: 0.9145\n",
      "Epoch 41/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1892 - acc: 0.9121 - val_loss: 0.1911 - val_acc: 0.9144\n",
      "Epoch 42/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1891 - acc: 0.9122 - val_loss: 0.1911 - val_acc: 0.9145\n",
      "Epoch 43/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1891 - acc: 0.9123 - val_loss: 0.1911 - val_acc: 0.9145\n",
      "Epoch 44/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1891 - acc: 0.9124 - val_loss: 0.1910 - val_acc: 0.9145\n",
      "Epoch 45/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1890 - acc: 0.9123 - val_loss: 0.1910 - val_acc: 0.9146\n",
      "Epoch 46/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1890 - acc: 0.9123 - val_loss: 0.1910 - val_acc: 0.9145\n",
      "Epoch 47/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1890 - acc: 0.9121 - val_loss: 0.1910 - val_acc: 0.9145\n",
      "Epoch 48/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1890 - acc: 0.9122 - val_loss: 0.1909 - val_acc: 0.9149\n",
      "Epoch 49/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1889 - acc: 0.9124 - val_loss: 0.1909 - val_acc: 0.9144\n",
      "Epoch 50/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1889 - acc: 0.9127 - val_loss: 0.1908 - val_acc: 0.9141\n",
      "Epoch 51/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1888 - acc: 0.9123 - val_loss: 0.1909 - val_acc: 0.9142\n",
      "Epoch 52/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1889 - acc: 0.9126 - val_loss: 0.1908 - val_acc: 0.9144\n",
      "Epoch 53/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1888 - acc: 0.9125 - val_loss: 0.1907 - val_acc: 0.9141\n",
      "Epoch 54/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1887 - acc: 0.9121 - val_loss: 0.1907 - val_acc: 0.9141\n",
      "Epoch 55/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1887 - acc: 0.9123 - val_loss: 0.1907 - val_acc: 0.9145\n",
      "Epoch 56/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1886 - acc: 0.9125 - val_loss: 0.1907 - val_acc: 0.9145\n",
      "Epoch 57/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1886 - acc: 0.9123 - val_loss: 0.1906 - val_acc: 0.9148\n",
      "Epoch 58/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1886 - acc: 0.9119 - val_loss: 0.1905 - val_acc: 0.9142\n",
      "Epoch 59/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1885 - acc: 0.9121 - val_loss: 0.1905 - val_acc: 0.9147\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1885 - acc: 0.9125 - val_loss: 0.1904 - val_acc: 0.9144\n",
      "Epoch 61/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1884 - acc: 0.9119 - val_loss: 0.1905 - val_acc: 0.9141\n",
      "Epoch 62/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1884 - acc: 0.9126 - val_loss: 0.1903 - val_acc: 0.9166\n",
      "Epoch 63/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1883 - acc: 0.9125 - val_loss: 0.1902 - val_acc: 0.9169\n",
      "Epoch 64/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1883 - acc: 0.9125 - val_loss: 0.1902 - val_acc: 0.9168\n",
      "Epoch 65/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1883 - acc: 0.9128 - val_loss: 0.1901 - val_acc: 0.9167\n",
      "Epoch 66/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1882 - acc: 0.9131 - val_loss: 0.1901 - val_acc: 0.9174\n",
      "Epoch 67/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1882 - acc: 0.9126 - val_loss: 0.1902 - val_acc: 0.9166\n",
      "Epoch 68/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1881 - acc: 0.9128 - val_loss: 0.1900 - val_acc: 0.9168\n",
      "Epoch 69/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1881 - acc: 0.9131 - val_loss: 0.1900 - val_acc: 0.9165\n",
      "Epoch 70/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1881 - acc: 0.9130 - val_loss: 0.1899 - val_acc: 0.9168\n",
      "Epoch 71/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1880 - acc: 0.9130 - val_loss: 0.1900 - val_acc: 0.9167\n",
      "Epoch 72/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1879 - acc: 0.9133 - val_loss: 0.1899 - val_acc: 0.9169\n",
      "Epoch 73/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1879 - acc: 0.9137 - val_loss: 0.1898 - val_acc: 0.9173\n",
      "Epoch 74/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1877 - acc: 0.9134 - val_loss: 0.1898 - val_acc: 0.9172\n",
      "Epoch 75/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1878 - acc: 0.9134 - val_loss: 0.1897 - val_acc: 0.9170\n",
      "Epoch 76/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1877 - acc: 0.9134 - val_loss: 0.1898 - val_acc: 0.9168\n",
      "Epoch 77/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1877 - acc: 0.9134 - val_loss: 0.1897 - val_acc: 0.9171\n",
      "Epoch 78/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1877 - acc: 0.9137 - val_loss: 0.1897 - val_acc: 0.9170\n",
      "Epoch 79/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1876 - acc: 0.9135 - val_loss: 0.1895 - val_acc: 0.9170\n",
      "Epoch 80/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1875 - acc: 0.9137 - val_loss: 0.1895 - val_acc: 0.9169\n",
      "Epoch 81/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1875 - acc: 0.9136 - val_loss: 0.1895 - val_acc: 0.9171\n",
      "Epoch 82/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1873 - acc: 0.9139 - val_loss: 0.1895 - val_acc: 0.9172\n",
      "Epoch 83/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1874 - acc: 0.9139 - val_loss: 0.1894 - val_acc: 0.9167\n",
      "Epoch 84/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1873 - acc: 0.9137 - val_loss: 0.1894 - val_acc: 0.9168\n",
      "Epoch 85/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1873 - acc: 0.9136 - val_loss: 0.1893 - val_acc: 0.9167\n",
      "Epoch 86/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1872 - acc: 0.9134 - val_loss: 0.1893 - val_acc: 0.9166\n",
      "Epoch 87/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1871 - acc: 0.9137 - val_loss: 0.1894 - val_acc: 0.9159\n",
      "Epoch 88/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1870 - acc: 0.9136 - val_loss: 0.1892 - val_acc: 0.9168\n",
      "Epoch 89/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1872 - acc: 0.9137 - val_loss: 0.1892 - val_acc: 0.9163\n",
      "Epoch 90/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1870 - acc: 0.9133 - val_loss: 0.1891 - val_acc: 0.9160\n",
      "Epoch 91/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1871 - acc: 0.9135 - val_loss: 0.1892 - val_acc: 0.9159\n",
      "Epoch 92/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1869 - acc: 0.9137 - val_loss: 0.1890 - val_acc: 0.9166\n",
      "Epoch 93/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1868 - acc: 0.9134 - val_loss: 0.1890 - val_acc: 0.9161\n",
      "Epoch 94/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1868 - acc: 0.9137 - val_loss: 0.1890 - val_acc: 0.9159\n",
      "Epoch 95/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1867 - acc: 0.9132 - val_loss: 0.1893 - val_acc: 0.9166\n",
      "Epoch 96/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1868 - acc: 0.9134 - val_loss: 0.1889 - val_acc: 0.9158\n",
      "Epoch 97/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1866 - acc: 0.9132 - val_loss: 0.1890 - val_acc: 0.9158\n",
      "Epoch 98/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1865 - acc: 0.9133 - val_loss: 0.1888 - val_acc: 0.9159\n",
      "Epoch 99/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1865 - acc: 0.9135 - val_loss: 0.1888 - val_acc: 0.9155\n",
      "Epoch 100/100\n",
      "28831/28831 [==============================] - 0s 2us/step - loss: 0.1865 - acc: 0.9136 - val_loss: 0.1887 - val_acc: 0.9160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a29d668>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "adamLooksForRoberto = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adamLooksForRoberto, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 239\n",
      "Trainable params: 239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28831 samples, validate on 12357 samples\n",
      "Epoch 1/100\n",
      "28831/28831 [==============================] - 1s 43us/step - loss: 0.3417 - acc: 0.8861 - val_loss: 0.2120 - val_acc: 0.8886\n",
      "Epoch 2/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.2090 - acc: 0.8868 - val_loss: 0.2068 - val_acc: 0.8886\n",
      "Epoch 3/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.2053 - acc: 0.8882 - val_loss: 0.2061 - val_acc: 0.9124\n",
      "Epoch 4/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.2038 - acc: 0.9104 - val_loss: 0.2046 - val_acc: 0.9113\n",
      "Epoch 5/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.2024 - acc: 0.9103 - val_loss: 0.2024 - val_acc: 0.9137\n",
      "Epoch 6/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.2010 - acc: 0.9109 - val_loss: 0.2011 - val_acc: 0.9145\n",
      "Epoch 7/100\n",
      "28831/28831 [==============================] - 1s 40us/step - loss: 0.1999 - acc: 0.9108 - val_loss: 0.2005 - val_acc: 0.9137\n",
      "Epoch 8/100\n",
      "28831/28831 [==============================] - 1s 39us/step - loss: 0.1989 - acc: 0.9117 - val_loss: 0.1994 - val_acc: 0.9123\n",
      "Epoch 9/100\n",
      "28831/28831 [==============================] - 1s 33us/step - loss: 0.1981 - acc: 0.9119 - val_loss: 0.1990 - val_acc: 0.9137\n",
      "Epoch 10/100\n",
      "28831/28831 [==============================] - 1s 36us/step - loss: 0.1975 - acc: 0.9114 - val_loss: 0.1988 - val_acc: 0.9133\n",
      "Epoch 11/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1967 - acc: 0.9113 - val_loss: 0.1982 - val_acc: 0.9133\n",
      "Epoch 12/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1961 - acc: 0.9121 - val_loss: 0.1974 - val_acc: 0.9135\n",
      "Epoch 13/100\n",
      "28831/28831 [==============================] - 1s 40us/step - loss: 0.1955 - acc: 0.9114 - val_loss: 0.1969 - val_acc: 0.9123\n",
      "Epoch 14/100\n",
      "28831/28831 [==============================] - 1s 38us/step - loss: 0.1950 - acc: 0.9120 - val_loss: 0.1969 - val_acc: 0.9137\n",
      "Epoch 15/100\n",
      "28831/28831 [==============================] - 1s 30us/step - loss: 0.1944 - acc: 0.9128 - val_loss: 0.1960 - val_acc: 0.9138\n",
      "Epoch 16/100\n",
      "28831/28831 [==============================] - 1s 32us/step - loss: 0.1939 - acc: 0.9136 - val_loss: 0.1963 - val_acc: 0.9141\n",
      "Epoch 17/100\n",
      "28831/28831 [==============================] - 1s 34us/step - loss: 0.1936 - acc: 0.9126 - val_loss: 0.1960 - val_acc: 0.9132\n",
      "Epoch 18/100\n",
      "28831/28831 [==============================] - 1s 32us/step - loss: 0.1931 - acc: 0.9125 - val_loss: 0.1957 - val_acc: 0.9136\n",
      "Epoch 19/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1926 - acc: 0.9128 - val_loss: 0.1949 - val_acc: 0.9141\n",
      "Epoch 20/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1923 - acc: 0.9131 - val_loss: 0.1950 - val_acc: 0.9137\n",
      "Epoch 21/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1919 - acc: 0.9129 - val_loss: 0.1941 - val_acc: 0.9138\n",
      "Epoch 22/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1913 - acc: 0.9126 - val_loss: 0.1940 - val_acc: 0.9140\n",
      "Epoch 23/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1911 - acc: 0.9122 - val_loss: 0.1936 - val_acc: 0.9135\n",
      "Epoch 24/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1907 - acc: 0.9120 - val_loss: 0.1934 - val_acc: 0.9137\n",
      "Epoch 25/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1904 - acc: 0.9125 - val_loss: 0.1927 - val_acc: 0.9147\n",
      "Epoch 26/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1899 - acc: 0.9130 - val_loss: 0.1922 - val_acc: 0.9139\n",
      "Epoch 27/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1898 - acc: 0.9131 - val_loss: 0.1912 - val_acc: 0.9117\n",
      "Epoch 28/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1891 - acc: 0.9128 - val_loss: 0.1925 - val_acc: 0.9132\n",
      "Epoch 29/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1892 - acc: 0.9119 - val_loss: 0.1912 - val_acc: 0.9156\n",
      "Epoch 30/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1888 - acc: 0.9119 - val_loss: 0.1905 - val_acc: 0.9153\n",
      "Epoch 31/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1883 - acc: 0.9126 - val_loss: 0.1916 - val_acc: 0.9136\n",
      "Epoch 32/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1882 - acc: 0.9122 - val_loss: 0.1896 - val_acc: 0.9157\n",
      "Epoch 33/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1879 - acc: 0.9129 - val_loss: 0.1893 - val_acc: 0.9173\n",
      "Epoch 34/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1872 - acc: 0.9126 - val_loss: 0.1894 - val_acc: 0.9150\n",
      "Epoch 35/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1868 - acc: 0.9120 - val_loss: 0.1884 - val_acc: 0.9118\n",
      "Epoch 36/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1865 - acc: 0.9129 - val_loss: 0.1884 - val_acc: 0.9162\n",
      "Epoch 37/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1863 - acc: 0.9126 - val_loss: 0.1886 - val_acc: 0.9131\n",
      "Epoch 38/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1855 - acc: 0.9127 - val_loss: 0.1880 - val_acc: 0.9137\n",
      "Epoch 39/100\n",
      "28831/28831 [==============================] - 1s 31us/step - loss: 0.1852 - acc: 0.9130 - val_loss: 0.1870 - val_acc: 0.9149\n",
      "Epoch 40/100\n",
      "28831/28831 [==============================] - 1s 38us/step - loss: 0.1846 - acc: 0.9128 - val_loss: 0.1861 - val_acc: 0.9134\n",
      "Epoch 41/100\n",
      "28831/28831 [==============================] - 1s 31us/step - loss: 0.1846 - acc: 0.9117 - val_loss: 0.1874 - val_acc: 0.9154\n",
      "Epoch 42/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1842 - acc: 0.9128 - val_loss: 0.1856 - val_acc: 0.9138\n",
      "Epoch 43/100\n",
      "28831/28831 [==============================] - 1s 30us/step - loss: 0.1836 - acc: 0.9125 - val_loss: 0.1856 - val_acc: 0.9144\n",
      "Epoch 44/100\n",
      "28831/28831 [==============================] - 1s 34us/step - loss: 0.1835 - acc: 0.9127 - val_loss: 0.1856 - val_acc: 0.9145\n",
      "Epoch 45/100\n",
      "28831/28831 [==============================] - 1s 46us/step - loss: 0.1829 - acc: 0.9129 - val_loss: 0.1847 - val_acc: 0.9149\n",
      "Epoch 46/100\n",
      "28831/28831 [==============================] - 1s 30us/step - loss: 0.1826 - acc: 0.9130 - val_loss: 0.1845 - val_acc: 0.9149\n",
      "Epoch 47/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1823 - acc: 0.9128 - val_loss: 0.1847 - val_acc: 0.9125\n",
      "Epoch 48/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1823 - acc: 0.9136 - val_loss: 0.1838 - val_acc: 0.9141\n",
      "Epoch 49/100\n",
      "28831/28831 [==============================] - 1s 30us/step - loss: 0.1817 - acc: 0.9135 - val_loss: 0.1847 - val_acc: 0.9133\n",
      "Epoch 50/100\n",
      "28831/28831 [==============================] - 1s 34us/step - loss: 0.1818 - acc: 0.9142 - val_loss: 0.1844 - val_acc: 0.9132\n",
      "Epoch 51/100\n",
      "28831/28831 [==============================] - 1s 40us/step - loss: 0.1813 - acc: 0.9136 - val_loss: 0.1832 - val_acc: 0.9141\n",
      "Epoch 52/100\n",
      "28831/28831 [==============================] - 1s 30us/step - loss: 0.1810 - acc: 0.9131 - val_loss: 0.1868 - val_acc: 0.9113\n",
      "Epoch 53/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1810 - acc: 0.9138 - val_loss: 0.1824 - val_acc: 0.9149\n",
      "Epoch 54/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1807 - acc: 0.9147 - val_loss: 0.1867 - val_acc: 0.9115\n",
      "Epoch 55/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1806 - acc: 0.9137 - val_loss: 0.1828 - val_acc: 0.9149\n",
      "Epoch 56/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1804 - acc: 0.9142 - val_loss: 0.1819 - val_acc: 0.9144\n",
      "Epoch 57/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1804 - acc: 0.9156 - val_loss: 0.1825 - val_acc: 0.9139\n",
      "Epoch 58/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1806 - acc: 0.9146 - val_loss: 0.1821 - val_acc: 0.9141\n",
      "Epoch 59/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1800 - acc: 0.9154 - val_loss: 0.1843 - val_acc: 0.9134\n",
      "Epoch 60/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1799 - acc: 0.9149 - val_loss: 0.1824 - val_acc: 0.9139\n",
      "Epoch 61/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1800 - acc: 0.9145 - val_loss: 0.1826 - val_acc: 0.9137\n",
      "Epoch 62/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1801 - acc: 0.9141 - val_loss: 0.1818 - val_acc: 0.9145\n",
      "Epoch 63/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1795 - acc: 0.9144 - val_loss: 0.1823 - val_acc: 0.9158\n",
      "Epoch 64/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1796 - acc: 0.9138 - val_loss: 0.1827 - val_acc: 0.9162\n",
      "Epoch 65/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1796 - acc: 0.9150 - val_loss: 0.1825 - val_acc: 0.9153\n",
      "Epoch 66/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1796 - acc: 0.9148 - val_loss: 0.1820 - val_acc: 0.9168\n",
      "Epoch 67/100\n",
      "28831/28831 [==============================] - 1s 27us/step - loss: 0.1798 - acc: 0.9153 - val_loss: 0.1820 - val_acc: 0.9134\n",
      "Epoch 68/100\n",
      "28831/28831 [==============================] - 1s 31us/step - loss: 0.1795 - acc: 0.9151 - val_loss: 0.1810 - val_acc: 0.9174\n",
      "Epoch 69/100\n",
      "28831/28831 [==============================] - 1s 30us/step - loss: 0.1795 - acc: 0.9146 - val_loss: 0.1819 - val_acc: 0.9163\n",
      "Epoch 70/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1794 - acc: 0.9160 - val_loss: 0.1822 - val_acc: 0.9134\n",
      "Epoch 71/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1794 - acc: 0.9148 - val_loss: 0.1818 - val_acc: 0.9137\n",
      "Epoch 72/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1795 - acc: 0.9149 - val_loss: 0.1830 - val_acc: 0.9146\n",
      "Epoch 73/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1794 - acc: 0.9142 - val_loss: 0.1813 - val_acc: 0.9152\n",
      "Epoch 74/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1792 - acc: 0.9148 - val_loss: 0.1813 - val_acc: 0.9167\n",
      "Epoch 75/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1791 - acc: 0.9151 - val_loss: 0.1809 - val_acc: 0.9171\n",
      "Epoch 76/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1793 - acc: 0.9153 - val_loss: 0.1811 - val_acc: 0.9153\n",
      "Epoch 77/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1792 - acc: 0.9152 - val_loss: 0.1808 - val_acc: 0.9150\n",
      "Epoch 78/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1792 - acc: 0.9154 - val_loss: 0.1819 - val_acc: 0.9153\n",
      "Epoch 79/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1791 - acc: 0.9155 - val_loss: 0.1810 - val_acc: 0.9149\n",
      "Epoch 80/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1791 - acc: 0.9154 - val_loss: 0.1818 - val_acc: 0.9151\n",
      "Epoch 81/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1789 - acc: 0.9161 - val_loss: 0.1811 - val_acc: 0.9174\n",
      "Epoch 82/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1790 - acc: 0.9158 - val_loss: 0.1815 - val_acc: 0.9181\n",
      "Epoch 83/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1791 - acc: 0.9149 - val_loss: 0.1831 - val_acc: 0.9144\n",
      "Epoch 84/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1791 - acc: 0.9154 - val_loss: 0.1814 - val_acc: 0.9170\n",
      "Epoch 85/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1791 - acc: 0.9155 - val_loss: 0.1808 - val_acc: 0.9176\n",
      "Epoch 86/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1791 - acc: 0.9151 - val_loss: 0.1809 - val_acc: 0.9181\n",
      "Epoch 87/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1786 - acc: 0.9159 - val_loss: 0.1824 - val_acc: 0.9128\n",
      "Epoch 88/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1789 - acc: 0.9162 - val_loss: 0.1808 - val_acc: 0.9171\n",
      "Epoch 89/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1790 - acc: 0.9143 - val_loss: 0.1805 - val_acc: 0.9161\n",
      "Epoch 90/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1790 - acc: 0.9162 - val_loss: 0.1809 - val_acc: 0.9175\n",
      "Epoch 91/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1785 - acc: 0.9154 - val_loss: 0.1812 - val_acc: 0.9173\n",
      "Epoch 92/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1786 - acc: 0.9163 - val_loss: 0.1808 - val_acc: 0.9164\n",
      "Epoch 93/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1789 - acc: 0.9157 - val_loss: 0.1815 - val_acc: 0.9152\n",
      "Epoch 94/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1788 - acc: 0.9155 - val_loss: 0.1810 - val_acc: 0.9162\n",
      "Epoch 95/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1785 - acc: 0.9160 - val_loss: 0.1808 - val_acc: 0.9166\n",
      "Epoch 96/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1785 - acc: 0.9166 - val_loss: 0.1815 - val_acc: 0.9149\n",
      "Epoch 97/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1784 - acc: 0.9174 - val_loss: 0.1835 - val_acc: 0.9135\n",
      "Epoch 98/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1788 - acc: 0.9155 - val_loss: 0.1815 - val_acc: 0.9158\n",
      "Epoch 99/100\n",
      "28831/28831 [==============================] - 1s 28us/step - loss: 0.1785 - acc: 0.9162 - val_loss: 0.1812 - val_acc: 0.9145\n",
      "Epoch 100/100\n",
      "28831/28831 [==============================] - 1s 29us/step - loss: 0.1785 - acc: 0.9155 - val_loss: 0.1844 - val_acc: 0.9121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a9a1fd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with sklearn.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network\n",
    "# create model\n",
    "def network1():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 90.95% (0.31%)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('net1', KerasClassifier(build_fn=network1, epochs=1, batch_size=5, verbose=0)))\n",
    "\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = cross_val_score(pipeline, X_train, y_train, cv=kfold)\n",
    "\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** is a classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts $P(Y=1)$ as a function of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main assumptions for Logistic Regression\n",
    "\n",
    "1. Logistic regression requires the dependent variable to be binary.\n",
    "2. The level $1$ of the dependent variable should represent the desired outcome.\n",
    "3. Logistic regression requires quite large sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.91\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10724   257]\n",
      " [  840   536]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95     10981\n",
      "          1       0.68      0.39      0.49      1376\n",
      "\n",
      "avg / total       0.90      0.91      0.90     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **precision** is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier to not label a sample as positive if it is negative.\n",
    "\n",
    "The **recall** is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The **F1 score** can be interpreted as a weighted harmonic mean of the precision and recall. F1 score reaches its best value at 1 and worst score at 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
